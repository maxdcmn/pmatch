name,email,profile_url,score,top_publication,top_abstract
Henrik Boström,bostromh@kth.se,https://www.kth.se/profile/henbos/,0.2586,Can local explanation techniques explain linear additive models?,"Local model-agnostic additive explanation techniques decompose the predicted output of a black-box model into additive feature importance scores. However, questions have been raised about the accuracy of these local additive explanations. We investigate this by testing whether several popular explanation methods can accurately explain the decisions of linear additive models. We show that even though the explanations produced by these techniques are linear and local by construction, they can still fail to fully reflect the true contribution of each feature to the model’s prediction, highlighting potential reliability issues in certain cases."
Hedvig Kjellström,hedvig@kth.se,https://www.kth.se/profile/hedvig,0.2571,Dessie: Disentanglement for Articulated 3D Horse Shape and Pose Estimation from Images,"In recent years, 3D parametric animal models have been developed to aid in estimating 3D shape and pose from images and video. While progress has been made for humans, it’s more challenging for animals due to limited annotated data. To address this, we introduce the first method using synthetic data generation and disentanglement to learn to regress 3D shape and pose. Focusing on horses, we use text-based texture generation and a synthetic data pipeline to create varied shapes, poses, and appearances, learning disentangled spaces. Our method, Dessie, surpasses existing 3D horse reconstruction methods and generalizes to other large animals like zebras, cows, and deer. See the project website at: https://celiali.github.io/Dessie/."
Danica Kragic Jensfelt,dani@kth.se,https://www.kth.se/profile/dani,0.2485,Disobeying Directions: Switching Random Walk Filters for Unsupervised Node Embedding Learning on Directed Graphs,"Unsupervised learning of node embeddings on directed graphs is challenging because directed edges break the symmetry that many embedding methods assume. This paper proposes a method that “disobeys” edge directions by switching random walk filters, effectively allowing information to flow in a balanced way on directed graphs. By leveraging switched random walks, the approach produces node embeddings that better capture the structure of directed networks. Experiments show that the learned embeddings lead to improved performance on downstream tasks compared to standard methods that do not account for edge direction or only rely on one-way random walks."
Tony Lindeberg,tony@kth.se,https://www.kth.se/profile/tony/,0.2418,A time-causal and time-recursive analogue of the Gabor transform,"This paper presents a time-causal analogue of the Gabor filter, as well as a fully time-causal and time-recursive analogue of the Gabor transform. The proposed framework enables time-frequency analysis over multiple temporal scales in a manner that is strictly causal (no access to future data) and recursive over time. In essence, the theory makes it possible to perform multi-scale time-frequency analysis in real time, akin to the Gabor transform, but without requiring acausal filtering."
Karl Henrik Johansson,kallej@kth.se,https://www.kth.se/profile/kallej,0.1918,Safe Reinforcement Learning Using Black-Box Reachability Analysis,"Reinforcement learning (RL) is capable of sophisticated motion planning and control, but ensuring safety during the learning process is challenging. This work integrates black-box reachability analysis into the RL loop to guarantee safety. At each decision step, reachability analysis is used as a safety filter to predict whether a given control action could lead to an unsafe state in the future. The RL agent’s actions are modified or vetoed based on this analysis, ensuring that the agent avoids unsafe trajectories while still learning an optimal policy. We demonstrate that this black-box reachability-based safe RL approach allows an agent to learn control policies that satisfy safety constraints, without significantly sacrificing performance or learning efficiency."
